<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Shuai Wang</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">menu</div>
<div class="menu-item"><a href="index.html">Home</a></div>
<div class="menu-item"><a href="research.html">Research</a></div>
<div class="menu-item"><a href="software.html">Software</a></div>
<div class="menu-item"><a href="publications.html">Publication</a></div>
<div class="menu-item"><a href="teaching.html">Teaching</a></div>
<div class="menu-item"><a href="demo.html" class="current">Demo</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Shuai Wang</h1>
</div>
<h3>Edge Federated Learning For Autonomous Vehicle Perception</h3>
<table class="imgtable"><tr><td>
<img src="./gifs/fl.gif" alt="alt text" width="960px" height="540px" />&nbsp;</td>
<td align="left"></td></tr></table>
<p>[UMAirComp] S. Wang, Y. Hong, R. Wang, Q. Hao, Y.-C. Wu, and D. W. K. Ng, “Edge federated learning via unit-modulus over-the-air computation,” IEEE Transactions on Communications, 2021. [Online]. Available: https:<i></i>arxiv.org<i>pdf</i>2101.12051.pdf.</p>
<ul>
<li><p>Edge federated learning (FL) is an emerging paradigm that trains a global parametric model from distributed datasets based on wireless communications. </p>
</li>
<li><p>We propose a unit-modulus over-the-air computation (UMAirComp) framework to facilitate efficient edge federated learning, which simultaneously uploads local model parameters and updates global model parameters via analog beamforming. </p>
</li>
<li><p>The proposed framework avoids sophisticated baseband signal processing, leading to low communication delays and implementation costs. </p>
</li>
<li><p>We demonstrate the implementation of UMAirComp-FL in a vehicle-to-everything autonomous driving perception platform. </p>
</li>
</ul>
<h3>CARLA-SUMO Integrated Simulation Platform</h3>
<table class="imgtable"><tr><td>
<img src="./gifs/sumo.gif" alt="alt text" width="960px" height="540px" />&nbsp;</td>
<td align="left"></td></tr></table>
<p>[CARLA] A. Dosovitskiy, G. Ros, F. Codevilla, A. Lopez, and V. Koltun, “Carla: An open urban driving simulator,” in Proceedings of the 1st Annual Conference on Robot Learning (CoRL), Mountain View, CA, Oct. 2017, pp. 1–16.</p>
<ul>
<li><p>This vedio shows that CARLA-SUMO integrated platform can provide high-fidelity environmentals, behaviors, and interfaces. </p>
</li>
<li><p>With CARLA-ROS bridge, hardware-in-the-loop simulation can be further developped. </p>
</li>
</ul>
<h3>Road Sensor Pose Optimization For Connected Autonomous Vehicle Perception</h3>
<table class="imgtable"><tr><td>
<img src="./gifs/v2x.gif" alt="alt text" width="960px" height="540px" />&nbsp;</td>
<td align="left"></td></tr></table>
<p>[FLCAVP] S. Wang, Q. Hao, D. W. K. Ng, Y. C. Eldar, and H. V. Poor, "Federated learning meets connected autonomous vehicle perception: Principles and implementation," submitted to IEEE for possible publication, 2021.</p>
<ul>
<li><p>The perception accuracy of ego-vehicle can be low due to occlusion. </p>
</li>
<li><p>Roadside sensors with broader field of views and highly-optimized hardware units can achieve more accurate and robust object detection performance. </p>
</li>
<li><p>Vehicle-to-infrastructure communication provides global bird-eye-views that overcomes the issue of occlusion. </p>
</li>
</ul>
<h3>Collision Avoidance Autonomous Vehicle Motion Prediction and Planning Based on Integrated Perception and V2V Communication</h3>
<table class="imgtable"><tr><td>
<img src="./gifs/lanechange.gif" alt="alt text" width="960px" height="540px" />&nbsp;</td>
<td align="left"></td></tr></table>
<p>[V2VMPC] S. Zhang, S. Wang, S. Yu, J.Q. Yu, and M. Wen, &lsquo;&lsquo;Collision avoidance autonomous vehicle motion prediction and planning based on integrated perception and V2V communication,&rsquo;&rsquo;  submitted to IEEE for possible publication, 2022.</p>
<ul>
<li><p>We design an autonomous vehicle motion planning strategy based on motion prediction and V2V communication.</p>
</li>
<li><p>Efficient and safe AV lane-change motion planning is achieved through the integration of the model predictive control and a deep learning techniques. </p>
</li>
<li><p>We implement the motion planning algorithm in Car Learning to Act (CARLA) system under various traffic conditions. </p>
</li>
</ul>
<h3>Distributed Dynamic Map Fusion via Federated Learning for Intelligent Networked Vehicles</h3>
<table class="imgtable"><tr><td>
<img src="./gifs/invs.gif" alt="alt text" width="960px" height="540px" />&nbsp;</td>
<td align="left"></td></tr></table>
<p>[INVS] Z. Zhang, S. Wang, Y. Hong, L. Zhou, and Q. Hao, “Distributed dynamic map fusion via federated learning for intelligent networked vehicles,” in Proc. IEEE ICRA’2021, Xi’an, China, May 2021.</p>
<ul>
<li><p>The technology of dynamic map fusion among networked vehicles has been developed to enlarge sensing ranges and improve sensing accuracies for individual vehicles. </p>
</li>
<li><p>We develop a three-stage fusion scheme to predict the number of objects effectively and to fuse multiple local maps with fidelity scores.</p>
</li>
<li><p>We develop a federated learning algorithm which fine-tunes feature learning networks distributively by aggregating model parameters.</p>
</li>
<li><p>We develop an ensemble distillation method to generate pseudo labels when human-based data annotation is  unavailable. </p>
</li>
</ul>
</td>
</tr>
</table>
</body>
</html>
